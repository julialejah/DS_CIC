{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing 1\n",
    "In the original dataset, there are some features have little impacts on whether the traffic is abnormal or not, such as timestamps and IP addresses. The timestamp records the time when the anomalous network traffic occurred, which are of little help in training our neural network, so we removed this feature. In addition, as an anomaly detection system, we hope it can classify the network traffics according to their behavioral characteristics, and should not be biased against the IP address, so we also deleted the column of feature.\n",
    "\n",
    "**So we under-sampled the normal traffics and only took 2 million records randomly**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termina importar\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from csv import reader\n",
    "pd.set_option('display.max_columns', 50)\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "print('termina importar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Thuesday-20-02-2018_TrafficForML_CICFlowMeter_80col\n",
      "0.0\n",
      "0\n",
      "Friday-02-03-2018_TrafficForML_CICFlowMeter\n",
      "99359.35\n",
      "737299\n",
      "Friday-16-02-2018_TrafficForML_CICFlowMeter\n",
      "112466.5375\n",
      "813953\n",
      "Friday-23-02-2018_TrafficForML_CICFlowMeter\n",
      "125573.725\n",
      "858249\n",
      "Thursday-15-02-2018_TrafficForML_CICFlowMeter\n",
      "138680.9125\n",
      "963336\n",
      "Thursday-22-02-2018_TrafficForML_CICFlowMeter\n",
      "151788.1\n",
      "1062975\n",
      "Wednesday-14-02-2018_TrafficForML_CICFlowMeter\n",
      "164895.2875\n",
      "1167374\n",
      "Wednesday-21-02-2018_TrafficForML_CICFlowMeter\n",
      "178002.475\n",
      "1234378\n",
      "Wednesday-28-02-2018_TrafficForML_CICFlowMeter\n",
      "191109.6625\n",
      "1270745\n",
      "Thursday-01-03-2018_TrafficForML_CICFlowMeter\n",
      "198773.4625\n",
      "1325289\n"
     ]
    }
   ],
   "source": [
    "# 10.1007/978-3-030-23502-4_12\n",
    "\n",
    "\n",
    "\n",
    "#categ_list = ['Benign', 'Infilteration', 'DDOS attack-LOIC-UDP', 'DDOS attack-HOIC', 'FTP-BruteForce', 'SSH-Bruteforce', 'Brute Force -Web', 'Brute Force -XSS', 'SQL Injection', 'DoS attacks-GoldenEye', 'DoS attacks-Slowloris', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Hulk', 'Bot', 'DDoS attacks-LOIC-HTTP']\n",
    "#cont_cat=[13484708, 161934, 1730, 686012, 193360, 187589, 611, 230, 87, 41508, 10990, 139890, 461912, 286191, 576191]\n",
    "#proporcion_categ = [15499,186,1,788,222,215,1,1,1,47,12,160,531,329,662]\n",
    "#154997\t1861\t20\t7885\t2223\t2156\t7\t3\t1\t477\t126\t1608\t5309\t3290\t6623\n",
    "#proporcion_cont = [1] * 15\n",
    "muestraDF = pd.DataFrame (columns=['Dst Port',' Protocol',' Timestamp',' Flow Duration',' Tot Fwd Pkts',' Tot Bwd Pkts',' TotLen Fwd Pkts',' TotLen Bwd Pkts',' Fwd Pkt Len Max',' Fwd Pkt Len Min',' Fwd Pkt Len Mean',' Fwd Pkt Len Std',' Bwd Pkt Len Max',' Bwd Pkt Len Min',' Bwd Pkt Len Mean',' Bwd Pkt Len Std',' Flow Byts/s',' Flow Pkts/s',' Flow IAT Mean',' Flow IAT Std',' Flow IAT Max',' Flow IAT Min',' Fwd IAT Tot',' Fwd IAT Mean',' Fwd IAT Std',' Fwd IAT Max',' Fwd IAT Min',' Bwd IAT Tot',' Bwd IAT Mean',' Bwd IAT Std',' Bwd IAT Max',' Bwd IAT Min',' Fwd PSH Flags',' Bwd PSH Flags',' Fwd URG Flags',' Bwd URG Flags',' Fwd Header Len',' Bwd Header Len',' Fwd Pkts/s',' Bwd Pkts/s',' Pkt Len Min',' Pkt Len Max',' Pkt Len Mean',' Pkt Len Std',' Pkt Len Var',' FIN Flag Cnt',' SYN Flag Cnt',' RST Flag Cnt',' PSH Flag Cnt',' ACK Flag Cnt',' URG Flag Cnt',' CWE Flag Count',' ECE Flag Cnt',' Down/Up Ratio',' Pkt Size Avg',' Fwd Seg Size Avg',' Bwd Seg Size Avg',' Fwd Byts/b Avg',' Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',' Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts',' Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',' Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']);\n",
    "muestra = []\n",
    "#print(muestra.shape)\n",
    "print(muestra)\n",
    "#file_list = ['Thursday-01-03-2018_TrafficForML_CICFlowMeter','Wednesday-28-02-2018_TrafficForML_CICFlowMeter']\n",
    "\n",
    "file_list = ['Thuesday-20-02-2018_TrafficForML_CICFlowMeter_80col','Friday-02-03-2018_TrafficForML_CICFlowMeter','Friday-16-02-2018_TrafficForML_CICFlowMeter',\n",
    "             'Friday-23-02-2018_TrafficForML_CICFlowMeter','Thursday-15-02-2018_TrafficForML_CICFlowMeter','Thursday-22-02-2018_TrafficForML_CICFlowMeter',\n",
    "             'Wednesday-14-02-2018_TrafficForML_CICFlowMeter','Wednesday-21-02-2018_TrafficForML_CICFlowMeter','Wednesday-28-02-2018_TrafficForML_CICFlowMeter',\n",
    "             'Thursday-01-03-2018_TrafficForML_CICFlowMeter']\n",
    "cont=0\n",
    "for i in file_list:\n",
    "    print (i)\n",
    "    print (len(muestra)/80)\n",
    "    print (cont)\n",
    "    with open(i+'.csv', 'r') as read_obj: \n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        if header != None:\n",
    "            # Iterate            over each row after the header in the csv\n",
    "            for row in csv_reader:\n",
    "                if  cont < 2000000 and row [-1] == 'Benign' and random.random() < 0.1:\n",
    "                    muestra.append(row)\n",
    "                    cont = cont +1\n",
    "                else: \n",
    "                    muestra.append(row)\n",
    "                    \n",
    "print(muestraDF.shape)\n",
    "muestraDF = pd.DataFrame (data=muestra,columns=['Dst Port',' Protocol',' Timestamp',' Flow Duration',' Tot Fwd Pkts',' Tot Bwd Pkts',' TotLen Fwd Pkts',' TotLen Bwd Pkts',' Fwd Pkt Len Max',' Fwd Pkt Len Min',' Fwd Pkt Len Mean',' Fwd Pkt Len Std',' Bwd Pkt Len Max',' Bwd Pkt Len Min',' Bwd Pkt Len Mean',' Bwd Pkt Len Std',' Flow Byts/s',' Flow Pkts/s',' Flow IAT Mean',' Flow IAT Std',' Flow IAT Max',' Flow IAT Min',' Fwd IAT Tot',' Fwd IAT Mean',' Fwd IAT Std',' Fwd IAT Max',' Fwd IAT Min',' Bwd IAT Tot',' Bwd IAT Mean',' Bwd IAT Std',' Bwd IAT Max',' Bwd IAT Min',' Fwd PSH Flags',' Bwd PSH Flags',' Fwd URG Flags',' Bwd URG Flags',' Fwd Header Len',' Bwd Header Len',' Fwd Pkts/s',' Bwd Pkts/s',' Pkt Len Min',' Pkt Len Max',' Pkt Len Mean',' Pkt Len Std',' Pkt Len Var',' FIN Flag Cnt',' SYN Flag Cnt',' RST Flag Cnt',' PSH Flag Cnt',' ACK Flag Cnt',' URG Flag Cnt',' CWE Flag Count',' ECE Flag Cnt',' Down/Up Ratio',' Pkt Size Avg',' Fwd Seg Size Avg',' Bwd Seg Size Avg',' Fwd Byts/b Avg',' Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',' Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts',' Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',' Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']);\n",
    "muestraDF=pd.read_csv(\"DF_undersample.csv\",sep=',')\n",
    "print(muestraDF.shape)\n",
    "print (pd.unique(muestraDF.iloc[:,-1].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muestraDF.to_csv('DF_undersample.csv', index = False)\n",
    "muestraDF=pd.read_csv(\"DF_undersample.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Preprocessing 2\n",
    "\n",
    "After completing the above works, we divide the dataset into training set, test set and validation set, which are 90%, 9% and 1% of the original data respectively. The training set is used for training, the validation set is used for rapid evaluation of the model during training, and the test set is used for final evaluation of the model. In addition, we noticed that there are too many normal network traffic samples in the dataset, which can easily affect the classification preference of the model. **So we under-sampled the normal traffics and only took 2 million records randomly**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(muestraDF.shape)\n",
    "print(muestraDF.isna().values.any())\n",
    "muestraDF=muestraDF.drop(columns=[' Timestamp'],axis=1)\n",
    "print(muestraDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=muestraDF.iloc[:,-1]\n",
    "X=muestraDF.iloc[:,0:78]\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "nom_cols=['Dst Port',' Protocol',' Flow Duration',' Tot Fwd Pkts',' Tot Bwd Pkts',' TotLen Fwd Pkts',' TotLen Bwd Pkts',' Fwd Pkt Len Max',' Fwd Pkt Len Min',' Fwd Pkt Len Mean',' Fwd Pkt Len Std',' Bwd Pkt Len Max',' Bwd Pkt Len Min',' Bwd Pkt Len Mean',' Bwd Pkt Len Std',' Flow Byts/s',' Flow Pkts/s',' Flow IAT Mean',' Flow IAT Std',' Flow IAT Max',' Flow IAT Min',' Fwd IAT Tot',' Fwd IAT Mean',' Fwd IAT Std',' Fwd IAT Max',' Fwd IAT Min',' Bwd IAT Tot',' Bwd IAT Mean',' Bwd IAT Std',' Bwd IAT Max',' Bwd IAT Min',' Fwd PSH Flags',' Bwd PSH Flags',' Fwd URG Flags',' Bwd URG Flags',' Fwd Header Len',' Bwd Header Len',' Fwd Pkts/s',' Bwd Pkts/s',' Pkt Len Min',' Pkt Len Max',' Pkt Len Mean',' Pkt Len Std',' Pkt Len Var',' FIN Flag Cnt',' SYN Flag Cnt',' RST Flag Cnt',' PSH Flag Cnt',' ACK Flag Cnt',' URG Flag Cnt',' CWE Flag Count',' ECE Flag Cnt',' Down/Up Ratio',' Pkt Size Avg',' Fwd Seg Size Avg',' Bwd Seg Size Avg',' Fwd Byts/b Avg',' Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',' Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts',' Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',' Active Min', 'Idle Mean', 'Idle Std', 'Idle Max','Idle Min']\n",
    "for i in nom_cols:\n",
    "    X[i]=pd.to_numeric(X[i], errors='coerce')\n",
    "    X[i] = X[i].fillna(X[i].mean())\n",
    "print(X.isna().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace (['DDOS attack-LOIC-UDP', 'DDOS attack-HOIC','DDoS attacks-LOIC-HTTP'],'DDoS')\n",
    "y.replace (['Brute Force -Web', 'Brute Force -XSS', 'SQL Injection'],'Web_attack')\n",
    "y.replace (['FTP-BruteForce', 'SSH-Bruteforce'],'Bruteforce')\n",
    "y.replace (['DoS attacks-GoldenEye', 'DoS attacks-Slowloris', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Hulk'],'DoS')\n",
    "\n",
    "#DDoS\t(DDOS attack-LOIC-UDP', DDOS attack-HOIC',DDoS attacks-LOIC-HTTP)\n",
    "#BOT\t(Bot)\n",
    "#Inf\t(Infilteration)\n",
    "#Web attack\t(Brute Force -Web', Brute Force -XSS', SQL Injection')\n",
    "#BF\t(FTP-BruteForce', SSH-Bruteforce')\n",
    "#DoS (DoS attacks-GoldenEye', DoS attacks-Slowloris', DoS attacks-SlowHTTPTest', DoS attacks-Hulk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.isna().values.any())\n",
    "\n",
    "\n",
    "X_Train, X_2, y_Train, y_2= train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "X_Test, X_Val, y_Test, y_Val = train_test_split(X_Train, y_Train, test_size=0.1, random_state=1) \n",
    "\n",
    "print(X_Train.isna().values.any())\n"
    "X_Val.to_csv('X_Val.csv', index = False)",
    "y_Val.to_csv('y_Val.csv', index = False)",
    "X_Test.to_csv('X_Test.csv', index = False)",
    "y_Test.to_csv('y_Test.csv', index = False)",
    "\n"



    
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Preprocessing 3\n",
    "Furthermore, we over-sampled the samples of Web attack and Infiltration attack by using SMOTE algorithm. Oversampling is only implemented in training set. After dividing the dataset, we shuffle the training set to ensure the loss value change smoothly during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(sampling_strategy='minority')\n",
    "print(X_Train.isna().values.any())\n",
    "X_smote, y_smote = oversample.fit_resample(X_Train, y_Train)\n",
    "print(type(oversample))\n",
    "print (X_smote.shape)\n",
    "X_smote.to_csv('X_smote.csv', index = False)\n",
    "y_smote.to_csv('y_smote.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
